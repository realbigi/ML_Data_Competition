{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q7A7AtktyJoE"
      },
      "source": [
        "\n",
        "\n",
        "* https://towardsdatascience.com/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee\n",
        "* https://www.digitalocean.com/community/tutorials/exploratory-data-analysis-python\n",
        "* https://experienceleague.adobe.com/docs/experience-platform/data-science-workspace/jupyterlab/eda-notebook.html?lang=en\n",
        "* https://www.datacamp.com/tutorial/categorical-data\n",
        "* https://seaborn.pydata.org/tutorial/categorical.html\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhypttryJoH"
      },
      "source": [
        "# Predictive model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEIndyqg7pZz"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "USQYpVZW7pZ0"
      },
      "source": [
        "Logistic regression, Lasso, and Ridge are three popular statistical techniques used in regression analysis. Here's a brief explanation of each:\n",
        "\n",
        "1. Logistic regression is a type of regression analysis used to model the probability of a binary response variable. It is commonly used in machine learning applications where the goal is to predict a binary outcome, such as whether a customer will buy a product or not. The logistic regression model estimates the relationship between a set of independent variables and a binary dependent variable by calculating the probability of the event occurring.\n",
        "\n",
        "2. Lasso, short for \"Least Absolute Shrinkage and Selection Operator,\" is a regularization technique used in regression analysis to prevent overfitting. It works by adding a penalty term to the regression equation that shrinks the coefficients of less important features to zero, effectively selecting only the most important features in the model. Lasso is useful when working with high-dimensional data, where there are many features but only a subset of them are relevant for the prediction task.\n",
        "\n",
        "3. Ridge regression is another regularization technique used in regression analysis to prevent overfitting. Like Lasso, it adds a penalty term to the regression equation, but instead of shrinking the coefficients to zero, it shrinks them towards zero. This helps to reduce the impact of multicollinearity, where two or more predictor variables are highly correlated, which can cause the regression coefficients to become unstable. Ridge is useful when working with data that has a high degree of multicollinearity.\n",
        "\n",
        "We will only use Ridge and Lasso model for Predictive purposes in this analysis\n",
        "\n",
        "https://www.datacamp.com/tutorial/tutorial-lasso-ridge-regression \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jZeyEkx7pZ2"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge, RidgeCV, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Import Data\n",
        "\n",
        "#Scale features\n",
        "scaler = StandardScaler()\n",
        "train_logistic = scaler.fit_transform(train_logistic)\n",
        "test_logistic = scaler.transform(test_logistic)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BgfVf55E7pZ3"
      },
      "source": [
        "### Logistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GxMIW497pZ4"
      },
      "outputs": [],
      "source": [
        "#Model\n",
        "lr = LinearRegression()\n",
        "\n",
        "#Fit model\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "#predict\n",
        "#prediction = lr.predict(X_test)\n",
        "\n",
        "#actual\n",
        "actual = y_test\n",
        "\n",
        "train_score_lr = lr.score(X_train, y_train)\n",
        "test_score_lr = lr.score(X_test, y_test)\n",
        "\n",
        "print(\"The train score for lr model is {}\".format(train_score_lr))\n",
        "print(\"The test score for lr model is {}\".format(test_score_lr))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1scv6i2Z7pZ5"
      },
      "source": [
        "### Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAmWoldf7pZ6"
      },
      "outputs": [],
      "source": [
        "#Ridge Regression Model\n",
        "ridgeReg = Ridge(alpha=10)\n",
        "\n",
        "ridgeReg.fit(X_train,y_train)\n",
        "\n",
        "#train and test scorefor ridge regression\n",
        "train_score_ridge = ridgeReg.score(X_train, y_train)\n",
        "test_score_ridge = ridgeReg.score(X_test, y_test)\n",
        "\n",
        "print(\"\\nRidge Model............................................\\n\")\n",
        "print(\"The train score for ridge model is {}\".format(train_score_ridge))\n",
        "print(\"The test score for ridge model is {}\".format(test_score_ridge))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2gJoKMFj7pZ8"
      },
      "source": [
        "### Lasso\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH9g18jF7pZ9"
      },
      "outputs": [],
      "source": [
        "#Lasso regression model\n",
        "print(\"\\nLasso Model............................................\\n\")\n",
        "lasso = Lasso(alpha = 10)\n",
        "lasso.fit(X_train,y_train)\n",
        "train_score_ls =lasso.score(X_train,y_train)\n",
        "test_score_ls =lasso.score(X_test,y_test)\n",
        "\n",
        "print(\"The train score for ls model is {}\".format(train_score_ls))\n",
        "print(\"The test score for ls model is {}\".format(test_score_ls))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qmvi0tiryJoH"
      },
      "source": [
        "## Description of best model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_nl6eC5yJoH"
      },
      "source": [
        "## Comparison with other models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vfz3GMpEyJoH"
      },
      "source": [
        "## Tuning parameter analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P0TjXT_WyJoH"
      },
      "source": [
        "## Model selection approach"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xreIXIk1yJoH"
      },
      "source": [
        "# Diagnostics and kaggle prediction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aMP_Cik4yJoH"
      },
      "source": [
        "## Diagnostics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yQppdTytyJoI"
      },
      "source": [
        "## Kaggle prediction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey6wlUE-yJoI"
      },
      "source": [
        "# Conclusion"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
